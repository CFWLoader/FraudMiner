\documentclass{article}

\usepackage{url}
%\usepackage{amsmath}
%\usepackage{amssymb}

%\DeclareMathOperator*{\argmin}{argmin}
%\DeclareMathOperator*{\argmax}{argmax}

\title{Overview of Parallel Graph Algorithms}
\date{2017-09-19}
\author{Evan Huang \\ cfwloader@gmail.com}

\begin{document}

	%\maketitle

	%\newpage

	\tableofcontents

	\pagenumbering{arabic}

	\newpage

	\section{Using Search Engine to discover}
	\subsection{Github}
	I search key words like \emph{distributed}, \emph{parallel} or \emph{giraph} to find the current progress for any papers, implemented codes.
	\subsubsection{Giraph}
	Firstly I found this project \emph{Giraph Classifier}\cite{giraph_classifier}. It's about label propagation.
	\newline
	There is a upper layer application\cite{dis_graph_ana} based on Giraph and GraphX, which implemented High Betweenness Set Extraction, Weakly Connected Components, Page Rank, Leaf Compression, and Louvain Modularity on them.

	\section{Brief of Parallel Graph Algorithms}
	Classic algorithms like \emph{Page Rank}, \emph{Single Source Shortest Path}, \emph{Randown Walks}, \emph{Triangle Count}, \emph{Connected Components}, \emph{etc.} are implemented as framework built-in demos. There is no need to talk about these algorithms.
	\begin{table}[!bhp]
	\begin{tabular}{|c|c|c|c|c|}
	\hline
	Algorithm					& 	Parallel 	& 	Published	& 	Open Souces	&	Platform(s)	\\
	\hline
	LPA							&	Yes			&	Yes			& 	Yes			&	GPU			\\
	\hline
	Louvain						&	Yes			&	Yes			&	Yes			&	GraphX		\\
	\hline
	K-Core Decomposition		& 	Yes			&	Yes			&	Yes			&	Giraph		\\
	\hline
	K-Means						&	Yes			&	Yes			&	Yes			&	Giraph 		\\
	\hline
	Influence Maximization		&	Yes			&	Yes			&	Yes			&	GPU,GraphX	\\
	\hline
	Stochastic Gradient Descend	&	Yes			&	Yes			&	Yes			&	Giraph 		\\
	\hline
	Graph Isomorphism			&	Yes			&	Yes			&	Yes			& 	CUDA		\\
	\hline
	Graph Coloring				&	Yes			&	Yes			& 	Yes			&	Giraph 		\\
	\hline
	Community Structure Dectection	& 	Yes		&	Yes			&	Yes			&	Giraph 		\\
	\hline
	Restricted Boltzmann Machine	& 	Yes		&	Unknown		&	Yes			&	Giraph 		\\
	\hline
	Non-negative Matrix Factorization	& 	Yes	&	Yes			&	Yes			&	GraphX		\\
	\hline
	Closeness Centrality 		&	Yes			&	Yes			& 	Yes			&	Multi-CPU	\\
	\hline
	k-Influential Community Search 	&	No 		&	No 			& 	No 			& 	None 		\\
	\hline
	Influence Maximization 		&	Yes			&	Yes			&	Yes			&	Unknown		\\
	\hline
	pSCAN(Chang)				&	Unknown		&	No 			&	No 			& 	None 		\\
	\hline
	PSCAN(Zhao)					& 	Yes			&	Yes			&	Unknown		&	MapReduce	\\
	\hline
	gSpan						&	Yes			& 	Yes			& 	Yes			& 	Java,CUDA,FPGA \\
	\hline
	DBScan						&	Yes			& 	Yes			& 	Yes			& 	MapReduce, FPGA \\
	\hline
	3-profiles					& 	Yes			&	Yes			&	Unknown		& 	GraphLab 	\\
	\hline
	4-profiles 					& 	Yes			& 	Yes			& 	Unknown 	& 	self-imp, GPU 	\\
	\hline

	\end{tabular}
	\caption{Brief of Parallel Graph Algorithms}
	\end{table}

	\section{Inspirations}
	\subsection{Community Detection}
	Lyu\cite{lyu2016scalable} states that select some best features from the graph information and then use these to eventually enlarge the subgraph to supergraph. 
	\newline
	Also, this algorithm needs to control the size of subgraphs(this maybe the disadvantage).
	\newline
	This idea inspired me of a new idea to process community detection cause the framework of this idea is like to Decision Tree. Can the algorithm use edge information to measure the score of features? And then use the feature to enlarge the graph to partitions(Communities).
	\subsection{Top-\emph{r} \emph{k}-Influential communities}
	Li\cite{li2015influential} proposed a method for mining Top-\emph{r} \emph{k}-Influential communities. I'm very interesting in this problem and wanna parallelize this algorithm. During searching the other papers, an idea has been lighted and it's that can I free the \emph{k} parameters for improving the correctness of this algorithm? Because the \emph{k} may severely limits the actual size of the communities therefore reduces the correctness of the result.
	\newline
	\textbf{Techs} used in this paper: \emph{k-core}, \emph{DFS}, \emph{ICP-Index}.
	\newline
	The k-core of a graph is the maximal subgraph with minimum (single node in the subgraph) degree at least k. \emph{k}-truss model cannot effectively find influential community.
	\newline
	In this paper, the influence value of a community is defined as the minimum weight of the nodes in that community. And the average weight of nodes in the community has drawbacks of robustness of outliers. Maybe I can change the definition of the influence value, such as upgraded average weight or others? While reading \cite{huang2015approximate}, a new idea of measuring the influence value emerged in my brain, that is, using some concept such triangle count in the community to stablize the influence value in case of outliers.
	\newline
	It's a possible to apply \emph{Louvain} on the graph and find the communities, then apply algorithms such as \emph{Page Rank} on the result to find the top \emph{k} communities as the influential communities. Also, this algorithm uses clustering to gather the nodes in the graph. Exactly, via \emph{k-core}, this algorithm can find communities with high-degree members. But does this algorithm consider these communities have "influence" to other communities with low score in the whole network? Can we apply page rank on the result to impore the correctnees of the result?
	\newline
	Find the best way to searching communities may help improving the correctness of ranking.
	\newline
	But this algorithm has been applied as an online algorithm and is fast enough(seconds for large k, r value on large graph, e.g. more than 1 billion edges.). It's very hard for me to conduct the experiment.
	\newline
	Fang\cite{fang2016effective} proposed a method on attributed graphs requiring the number of keywords' combinations. And when counting the combinations, this methods adopted FP-Growth\cite{han2002fp}.
	\newline
	Also Huang\cite{huang2016attribute} mentioned that most of graph algorithms ignores the attributes on the graphs. This inpired me to do the work that apply some attribute algorithm based on some non-attributes algorithm to improve the confidence of them.

	\begin{appendix}
		\section{References}
		\bibliography{opga_refs}
		\bibliographystyle{ieeetr}
	\end{appendix}

\end{document}