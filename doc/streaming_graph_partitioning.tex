\documentclass{article}

\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\title{Overview of Streaming Graph Partitioning}
\date{2017-06-21}
\author{Evan Huang \\ cfwloader@gmail.com}

\begin{document}

	\maketitle

	\newpage

	\tableofcontents

	% \pagenumbering{gobble}
	\pagenumbering{arabic}

	\newpage
	\section{Goals}
	\subsection{Evenly partitioning graphs into distributed systems}
	\subsection{Minimizing the cost of executing the queries}
	\subsection{Fastly collecting the graph information}

	\newpage
	\section{Problmes and current progress}
	\subsection{Problems}
	\subsubsection{Cycle Graph}
	This problem is mentioned by Stanton \emph{et al.}\cite{stanton2012streaming}, and this paper also proposed that the best performing heuristic is a weighted variant of the greedy algorithm. There are there three typical graph streaming orders considered in this page:\newline
	1. Beneath First Search.\newline
	2. Depth First Search.\newline
	3. Random.\newline

	\subsubsection{Inseparable Problem}
	I tested the use of \textbf{Giraph}\cite{giraph} and found out that it still can not parallelly handle graph though this framework is based on the hadoop\cite{hadoop}.

	\subsection{Current Progress}
	\subsubsection{Graph Partitioning}
	METIS\cite{metis} is the main-stream algorithm to partition the graph. Though so many years passed, the efficiency is still low in my personal opinion based on the evidence\cite{salihoglu2013gps:}. But There are now more inspiration. And GPS system useses an in-memory map to record where the node stored.
	\subsubsection{Partitional Heuristics}
	Stanton \emph{et al.}\cite{stanton2012streaming} also summed up 10 heuristics for partitioning.(\emph{ind} indicates the which machine the node belongs to.)\newline
	1. \textbf{Balanced} - \begin{equation} \emph{ind} = \mathop{\argmin}_{i\in[k]}{\{|P^t(i)|\}} \end{equation}
	2. \textbf{Chunking} - \begin{equation} \emph{ind} = \lceil t/C \rceil \end{equation}						% floor
	3. \textbf{Hashing} - \begin{equation} H(\emph{v}) = (\emph{v}~mod~\emph{k})~+~1 \end{equation}
	4. \textbf{(Weighted) Deterministic Greedy} - \begin{equation} \emph{ind}=\mathop{\argmax}_{i\in[k]}{\{|P^t(\emph{i})\cap\Gamma(\emph{v})|\emph{w}(\emph{t},\emph{i})\}} \end{equation}
	5. \textbf{(Weighted) Randomized Greedy} - \begin{equation} \emph{Pr(i)}=|P^t(\emph{i})\cap\Gamma(\emph{v})|\emph{w}(\emph{t},\emph{i})/Z \end{equation}
	6. \textbf{(Weighted) Triangles} - 
	\begin{equation}
		\mathop{\argmax}_{i\in[k]}{\{\frac{|\emph{E}(P^t(\emph{i})\cap\Gamma(\emph{v}), P^t(\emph{i})\cap\Gamma(\emph{v}))|}
		{\binom{|P^t(\emph{i})\cap\Gamma(\emph{v})|}{2}}\emph{w}(\emph{t},\emph{i})\}}
	\end{equation}
	7. \textbf{Balance Big}
	The following heuristics all use a buffer.\newline
	8. \textbf{Prefer Big}\newline
	9. \textbf{Avoid Big}\newline
	10.\textbf{Greedy EvoCut}\cite{andersen2009finding}

	\subsubsection{Giraph}
	Giraph is a iterative graph processing computational framework based on Map-Reduced frameworkd(Hadoop provides).
	\textbf{Related Bases}\newline
	\textbf{Hadoop.} Hadoop provides the distributive data store system. It is the main-stream open source implementation of GFS\cite{ghemawat2003the}.\newline
	\textbf{Map Reduced Framework.}\cite{lammel2008google's} This framework provides cluster-computing function. The computational process will be \textbf{\emph{mapped}} to several or more sub compu tational processes. After individual processes finished, \textbf{Bulk Synchronous Parallelism}\cite{gerbessiotis1994direct} will happens to control the iteration. All sub processes will be \text{\emph{reduced}} to the result.\newline
	But in my current experiment configurations, hadoop performs badly in the version problem. The stable and industry-used version is 0.22, the version Giraph requires is 1.2.1, HAMA\cite{seo2010hama:} requires 2.7.0 with zookeeper. Twitter Storm\cite{storm} is also such a distibutive computational framework as Giraph but requires more facilities.

	\subsubsection{GraphChi}
	\textbf{GraphChi}\cite{kyrola2012graphchi:} is a graph computation framework. Different with Map-Reduces Computation frameworks and distributive graph store system, GraphChi uses single personal computer to compute big graph(over millions of nodes). It uses \textbf{sorted source node number(ID)} to divide the graph to shards. Once we use GraphChi as the framework, that means we have to preprocess the ID of nodes.
	\newline
	\textbf{Shining Points}
	\newline
	\textbf{Evolving Graphs Supports.}
	\newline
	\textbf{Less communicating produres.} GraphChi programs are similar to those written for Pregel\cite{malewicz2009pregel:} or GraphLab\cite{low2014graphlab:}. But those programs depend on Message Passing Interface(MPI)\cite{meyer1993message-passing}, GraphChi programs directly modify the value of vertex.
	\newline
	% \subsubsection{Shortages}
	\textbf{Shortages:}
	\newline
	\textbf{1. Graph Traversal-like Algorithms.} Such this algorithms require loading neighbor nodes, that means scanning a complete memory-shard. Under such situation, GraphChi would degenerate to linear loading process.
	\newline
	\textbf{2. Big part load.} GraphChi requires full load of in-edges.
	\newline
	\textbf{3. Not automatic enough.} GraphChi would not automatically detect the available RAM of user PC. It needs explicit program parameters.

	\subsubsection{PowerGraph}
	\textbf{PowerGraph}\cite{gonzalez2012powergraph:} is a distributive version of GraphChi(as my temporary opinion). It performs well in the papers I viewed. It also uses synchronous model \emph{GAS} - \emph{Gather}, \emph{Apply}, \emph{Scatter}. The \emph{Gather} process is collecting the neighbors' information, the \emph{Apply} is applying some function to calculate the vertex's value and the \emph{Scatter} is updating the neighbors' value.

	\subsubsection{TurboGraph}
	\textbf{TurboGraph}\cite{han2013turbograph:} is a parallel IO and computation framework on a single PC. According to the paper's content, TurboGraph uses a mapping method to record the store location of vertexes.
	\newline
	\textbf{\emph{pin-and-slide}}
	\newline
	\textbf{\emph{column view}}

	\subsubsection{Pregel+}
	This is a enhanced implementation of Pregel. \cite{lu2014large-scale} evaluated main-stream graph computing system and Pregel takes the best overall performances.

	\newpage
	\section{Experiments}
	The following graph processing frameworks are simply tested and have some briefs:\newline
	1. Giraph\newline
	2. GraphChi\newline
	These have configuration problems, mostly due to the incompatible version of Hadoop:\newline
	1. HAMA\newline
	2. Storm\newline
	3. TurboGraph. Access Forbidden from server.\newline
	These are marked and waiting for being test:\newline
	1. GraphLab\newline
	2. PowerGraph\newline

	\subsection{Giraph}
	\textbf{Exceptions.} When the graph's size reaches about 100,000 nodes. \emph{OutOfMemory} exception will occur with Json format file. The reason is the map-reduced framework will just dispatch 2 JobTrackers, one for searching Workers and one for real computation. Once the workers job finished, the searching JobTrackers terminated, left the worker. In my experiments, map-reduced framework fails to dispatch multi workers. The only worker can not stand the high memory cost and OutOfMemory exception happens when only worker is loading the nodes.
	\subsection{GraphChi}
	\textbf{Result.} With the size of millions of nodes(Random Generated), GraphChi successfully deployed Page Rank\cite{pagerank} on this graphs and got the result.

	\newpage
	\section{Personal heuristics}
	\subsection{Cross adjacency matrix}
	General idea is transform the graph into a table with fixed rows and columns. The links are not only horizonal but vertical. But the main issue is how to handle the cross problem. For example, there are three links between 3 nodes. Once we stored as '1-2-3' then we how to express the direct link '1-3'?

	\subsection{Ideas spring from the output of the 'streaming'}
	Section 1 specifies the requirement of such a streaming graph handling system. And the method\cite{stanton2012streaming} purely considers the partitioning problems. Maybe we should start from the goals and the one of goals is Minimizing the cost of querying. Once we take this goal, we might not treat the partitioning problem so important. It means evenly partitioning the graph is not the key problem, it's the fastly collecting the graph information.

	\subsection{Distributive GraphChi? Or Metis + GraphChi?}

	\subsection{Viewing the graph as a sphere}
	This is my personal inspiration. What if we view the graph as a sphere in 3 dimensions or circle in 2 dimensions. The vertex, with less links, may more probable be placed to the posistion near the edge of the sphere(circle). We can start graph cutting work with such this vertexes. Then use some techs, such as random walk, to find the middle position of the sphere. The links of edge vertexes and middle position might be the base of cutting the sphere.
	\subsubsection{Can we apply some mathematical methods on such a 'sphere'?}
	Such as doing some integrals on this sphere to find the cutting hyperplane and evenly dividing this objects?

	\newpage
	\begin{appendix}
		\section{References}
		\bibliography{refs}
		\bibliographystyle{ieeetr}
	\end{appendix}

\end{document}
